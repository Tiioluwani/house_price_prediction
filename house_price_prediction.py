# -*- coding: utf-8 -*-
"""House price prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GzwgpIvkIn4f94QVYTjJgsyOQrN565Md
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
import sklearn.metrics

! pip install comet-ml

from comet_ml import Experiment

from google.colab import files
uploaded =files.upload()

import  io
data=pd.read_csv(io.BytesIO(uploaded['data.csv']))
data.head()

target = data['MEDV']
target

X = data
y = target

# Splitting dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)

# Check for NaN values in the dataset
nan_values = data.isnull().values.any()

if nan_values:
    print("The dataset contains NaN values.")
else:
    print("The dataset does not contain NaN values.")

from sklearn.linear_model import LinearRegression

# Dealing with a NaNs value using imputation method
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression

# Create a pipeline with an imputer and a linear regression model
pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),  # You can change strategy as needed
    ('model', LinearRegression())
])

# Fit the pipeline on the training data
pipeline.fit(X_train, y_train)

# We create a Comet.ML experiment and deploy the model
experiment = Experiment(api_key='', project_name ='House_price_prediction')

# Logging our data statistics
experiment.log_dataset_hash('data.csv')

# Log hyperparameters and configurations
experiment.log_parameters({"learning_rate": 0.001, "batch_size": 32})

# We define the model and its parameters
model_definition = {
    'model': pipeline,
    'hyperparameters': {'regularization': 0.01}
}

from sklearn.metrics import r2_score

# Predict using the trained model
y_pred = pipeline.predict(X_test)  # Assuming X_test is your test data

# Calculate R-squared
r_squared = r2_score(y_test, y_pred)

# Log R-squared as a dictionary
experiment.log_metrics({"R-squared": r_squared})

import joblib

# Assuming 'imputer' and 'model' are fitted objects in your pipeline
imputer = pipeline.named_steps['imputer']
model = pipeline.named_steps['model']

# Save the components as separate files using joblib or pickle
joblib.dump(imputer, 'imputer.joblib')
joblib.dump(model, 'model.joblib')

# Log the saved components
experiment.log_asset('imputer.joblib')
experiment.log_asset('model.joblib')

experiment.set_name('House Price Prediction')

experiment.end()